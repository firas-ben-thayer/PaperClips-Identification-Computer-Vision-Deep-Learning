# General description:
This model is used to differentiate between a good paperclip and a broken one.
# Model description:
A pre-trained VGG16 model is used so the image dimensions must be changed to (224,224,3) before predicting it.
